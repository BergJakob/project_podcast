{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Speech Recognition"
      ],
      "metadata": {
        "id": "Vae-Q-rH-CA4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svTOjmxq9jjQ"
      },
      "outputs": [],
      "source": [
        "pip install SpeechRecognition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr"
      ],
      "metadata": {
        "id": "MaTibGbh9--W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "AUDIO_FILE = path.join(path.dirname(path.realpath(\"test.wav\")), \"test.wav\")"
      ],
      "metadata": {
        "id": "p4d5-1pm9vSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = sr.Recognizer()\n",
        "with sr.AudioFile(AUDIO_FILE) as source:\n",
        "    audio = r.record(source)"
      ],
      "metadata": {
        "id": "giCzYHNT99FU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # for testing purposes, we're just using the default API key\n",
        "    # to use another API key, use `r.recognize_google(audio, key=\"GOOGLE_SPEECH_RECOGNITION_API_KEY\")`\n",
        "    # instead of `r.recognize_google(audio)`\n",
        "    print(r.recognize_google(audio))\n",
        "except sr.UnknownValueError:\n",
        "    print(\"Google Speech Recognition could not understand audio\")\n",
        "except sr.RequestError as e:\n",
        "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))"
      ],
      "metadata": {
        "id": "P5FEU_zj_Mrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Rule-Based Named-Entity-Recognition"
      ],
      "metadata": {
        "id": "btv4ZfGV_oIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. RBNER - LAGE\n",
        "\n"
      ],
      "metadata": {
        "id": "PC-MYZ6OBMMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy.matcher import Matcher, PhraseMatcher\n",
        "from spacy.pipeline import EntityRuler\n",
        "from spacy import displacy\n",
        "from spacy.lang.de import German\n",
        "from spacy.lang.en import English"
      ],
      "metadata": {
        "id": "MUqKMiHVBvoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_german = spacy.load(\"de_core_news_sm\", exclude=\"ner\") \n",
        "nlp_german = German()"
      ],
      "metadata": {
        "id": "57KfyQbOBLYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "german_ruler = nlp_german.add_pipe(\"entity_ruler\", config={\"validate\":True})"
      ],
      "metadata": {
        "id": "wuGdtlcOBTGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('XXX_LAGE.txt', 'r') as file:\n",
        "    lage = file.read().replace('\\n',' ')"
      ],
      "metadata": {
        "id": "Tuqz-cvYBWk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('parteien.txt', 'r') as file:\n",
        "    parteien = file.read()\n",
        "    \n",
        "parteien_list = parteien.split(\"\\n\")\n",
        "\n",
        "parteien_list"
      ],
      "metadata": {
        "id": "RmJVG-DgFAtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('politiker_innen.txt', 'r') as file:\n",
        "    politiker_innen = file.read()\n",
        "    \n",
        "politiker_innen_list = politiker_innen.split(\"\\n\")    \n",
        "\n",
        "politiker_innen_list"
      ],
      "metadata": {
        "id": "j5Q25TewFAtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('parteien.txt', 'r') as file:\n",
        "    parteien = file.read()\n",
        "    \n",
        "parteien_list = parteien.split(\"\\n\")\n",
        "\n",
        "parteien_list"
      ],
      "metadata": {
        "id": "__RL-VBAB2f7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parteien_patterns = [\n",
        "    {\"label\": \"PARTEI\", \"pattern\": str(partei)} for partei in list(nlp_german.pipe(parteien_list))\n",
        "]\n",
        "politiker_innen_patterns = [\n",
        "    {\"label\": \"POLITIKER_IN\", \"pattern\": str(politiker_in)} for politker_in in list(nlp_german.pipe(politiker_innen_list))\n",
        "]\n",
        "\n",
        "# Schritt 4.3: Zusammenführen der Patterns zu einer Liste\n",
        "patterns = parteien_patterns + politiker_innen_patterns\n",
        "patterns"
      ],
      "metadata": {
        "id": "05U_Oa_JFAtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "german_ruler.add_patterns(patterns)"
      ],
      "metadata": {
        "id": "OH-1fgtaCncP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bundestag_protokoll_text_processed = nlp_german(lage)"
      ],
      "metadata": {
        "id": "B5JvYAtGCoQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. RBNER - SPIEGEL"
      ],
      "metadata": {
        "id": "5TmPuQ_VFAtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_german = spacy.load(\"de_core_news_sm\", exclude=\"ner\") \n",
        "nlp_german = German()"
      ],
      "metadata": {
        "id": "saSc5oZnFAtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "german_ruler = nlp_german.add_pipe(\"entity_ruler\", config={\"validate\":True})"
      ],
      "metadata": {
        "id": "x3QK2SLwFAto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('XXX_SPIEGEL.txt', 'r') as file:\n",
        "    spiegel = file.read().replace('\\n',' ')"
      ],
      "metadata": {
        "id": "BuUBf2e2FAto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "german_ruler.add_patterns(patterns)"
      ],
      "metadata": {
        "id": "ALnjjoygFAtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bundestag_protokoll_text_processed = nlp_german(spiegel)"
      ],
      "metadata": {
        "id": "ljZfe4l5FAtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. RBNER - FAZ"
      ],
      "metadata": {
        "id": "zxoPYAbvJQeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_german = spacy.load(\"de_core_news_sm\", exclude=\"ner\") \n",
        "nlp_german = German()"
      ],
      "metadata": {
        "id": "6SbaQcr2JQeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "german_ruler = nlp_german.add_pipe(\"entity_ruler\", config={\"validate\":True})"
      ],
      "metadata": {
        "id": "JoLvqdDlJQeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('XXX_FAZ.txt', 'r') as file:\n",
        "    faz = file.read().replace('\\n',' ')"
      ],
      "metadata": {
        "id": "1WOWBZX_JQeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "german_ruler.add_patterns(patterns)"
      ],
      "metadata": {
        "id": "ezA03VfyJQeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bundestag_protokoll_text_processed = nlp_german(faz)"
      ],
      "metadata": {
        "id": "5oizSvsRJQeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Sentiment-Analyse"
      ],
      "metadata": {
        "id": "FgkZJ9NpLUoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "TQtHaRwDLYtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import matthews_corrcoef, f1_score, recall_score, precision_score, make_scorer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "from statistics import mean\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "import torch\n",
        "from sklearn.metrics import matthews_corrcoef, f1_score, recall_score, precision_recall_fscore_support, precision_score, make_scorer"
      ],
      "metadata": {
        "id": "htBCUB3ELZKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wir verwenden den AutoTokenizer, da er automatisch erkennt, welcher Tokenizer\n",
        "# benutzt werden muss und für welches Modell, z.B. BERT/T5.\n",
        "# Grund: Modelle müssen teilweise unterschiedlich tokenisiert werden\n",
        "from transformers import AutoTokenizer \n",
        "\n",
        "# als \"Checkpoint\" wird das Transformer-Model, das wir nutzen, bezeichnet\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "# hier laden wir den Tokenizer unseres Checkpoints herunter und speichern ihn\n",
        "# in einer Variable\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "KA91l-kBLZNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "raw_inputs = [\n",
        "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "    \"I hate this so much!\",\n",
        "]\n",
        "\n",
        "# nun wenden wir den Tokenizer auf den Rohtext an. Das Ergebnis wird in einer \n",
        "# Variable gespeichert und im Anschluss für das Model verwendet.\n",
        "\n",
        "# padding = True => BERT kann Sätze mit einer Länge von maximal 512 Tokens verarbeiten.\n",
        "# Wenn padding = True werden kürzere Sequenzen auf die maximale Länge im Korpus (<=512 Token) gestreckt bzw. aufgefüllt\n",
        "\n",
        "# truncation = True => enthält eine Sequenz mehr Token als zulässig sind, werden die überschüssigen Tokens entfernt\n",
        "\n",
        "# return_tensors = \"pt\" => spezifiziert den Tensor-Typ, den wir zurückerhalten: \n",
        "# pt = PyTorch, tf = TensorFlow, np = NumPy\n",
        "model_inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "# So sieht der Model-Input aus...\n",
        "pprint(model_inputs)"
      ],
      "metadata": {
        "id": "FQXVNLolLZX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 => zwei Input-Sätze\n",
        "# 16 => Sequence Length, also die maximale Tokenlänge\n",
        "# 768 => Anzahl der Dimensionen des Vektors\n",
        "pprint(outputs.last_hidden_state.shape)"
      ],
      "metadata": {
        "id": "kBd9dquWL-IZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "# Indem wir das AutoModelForSequenceClassification verwenden, können wir nun auf\n",
        "# den Head zugreifen\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "outputs = model(**model_inputs)\n",
        "pprint(outputs)"
      ],
      "metadata": {
        "id": "Jfh9YLEJL-QR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Der Head-Output enthält sogenannte logits\n",
        "# 2 => Anzahl Sätze\n",
        "# 2 => Anzahl Labels\n",
        "pprint(outputs.logits.shape)"
      ],
      "metadata": {
        "id": "9k1C8vfwL-Ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "pprint(predictions)"
      ],
      "metadata": {
        "id": "Y-bJzAmCL-XZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mit diesem Befehl können wir auf Model Config zugreifen und herausfinden, welche\n",
        "# Indexposition welchem Label entspricht\n",
        "model.config.id2label"
      ],
      "metadata": {
        "id": "U4Xy7bLKL-aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "evtl vereinfachen als Pipe\n",
        "Evaluation\n",
        "Tabellarische Übersicht möglich als Output (Freq etc)"
      ],
      "metadata": {
        "id": "_GgYCK_mMfFq"
      }
    }
  ]
}